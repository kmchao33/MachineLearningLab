{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSON files to TXT files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since someone has already preprocessed all the original PDF files for business report, what we got is the human-readable JSON files, which is quite nice. Nevertheless, there are so much useless information inside. Therefore, we decide to extract useful information from JSON file and convert to TXT file, in order to speed up the processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure all data files are extracted under /json_data folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute path\n",
    "ABSOLUTE_SOURCE_PATH = '/home/bit/ma0/LabShare/data/chui_ma/json_data/'\n",
    "ABSOLUTE_TARGET_PATH = '/home/bit/ma0/LabShare/data/chui_ma/txt_data/'\n",
    "\n",
    "# relative path\n",
    "RELATIVE_SOURCE_PATH = '../json_data/'\n",
    "RELATIVE_TARGET_PATH = '../txt_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Extract paragraphs from JSON files and write into TXT file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From json files, only extract useful *content* whose type is *paragraph*. Meanwhile, set several variables to monitor the file conversion.\n",
    "- successful_files: list, save all files that have been successfully read or extract infomation\n",
    "- failure_files: list, save all files that fail to be read or extract infomation\n",
    "- progress: int, keep track the number of files that have been processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractContent(filename):\n",
    "    with open(root+'/'+f, 'r') as freader, open(filename, 'w') as fwriter:\n",
    "        # only extract 'content' from json file\n",
    "        for line in freader:\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                if obj['type'] == 'paragraph':\n",
    "                    fwriter.write(obj['content'])\n",
    "            except:\n",
    "                # skip JSON decode error\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all files has been processeds been processed\n",
      "CPU times: user 33.4 s, sys: 1.93 s, total: 35.3 s\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# keep track on the success/failure of files\n",
    "successful_files = []\n",
    "failure_files = []\n",
    "\n",
    "# monitor the file process\n",
    "progress = 0\n",
    "progress_count = 0\n",
    "\n",
    "if not os.path.exists(RELATIVE_TARGET_PATH):\n",
    "    # create target folder to save processed text\n",
    "    os.makedirs(RELATIVE_TARGET_PATH)\n",
    "\n",
    "for root, dirs, files in os.walk(RELATIVE_SOURCE_PATH):\n",
    "    file_count = len(files)\n",
    "    for f in files:\n",
    "        progress += 1\n",
    "        progress_count += 1\n",
    "        try:\n",
    "            filename = RELATIVE_TARGET_PATH + f.split('.json')[0]\n",
    "            extractContent(filename)\n",
    "            successful_files.append(filename)\n",
    "        except:\n",
    "            failure_files.append(filename)\n",
    "        if progress_count % 200 == 0:\n",
    "            print('{:6.2%} of the total files has been processed'.format(\n",
    "                progress/file_count), end='\\r')\n",
    "        if progress_count == file_count:\n",
    "            print('all files has been processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1655 files succesfully processed. 0 files failed.\n"
     ]
    }
   ],
   "source": [
    "#quick check on file success/failure\n",
    "print('{} files succesfully processed. {} files failed.'.format(len(successful_files), len(failure_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conversion, we would like to do file [Preprocessing](02-Preprocessing.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
