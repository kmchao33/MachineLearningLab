{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 16 ms, total: 1.92 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# obtain term-frequency matrix\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "word2index = {}\n",
    "document2index = {}\n",
    "index2document = {}\n",
    "document_word_vectors = {}\n",
    "w_cnt = 0\n",
    "d_cnt = 0\n",
    "for root, dirs, files in os.walk('./data/paragraph/'):\n",
    "    for f in files:\n",
    "        document_word_vectors[f] = []\n",
    "        document2index[f] = d_cnt\n",
    "        index2document[d_cnt] = f\n",
    "        d_cnt+=1\n",
    "        with open(root+'/'+f) as fs:\n",
    "            try:\n",
    "                text = fs.read()\n",
    "                words = textPreprocess(text)\n",
    "                for w in words:\n",
    "                    if w not in word2index:\n",
    "                        word2index[w] = w_cnt\n",
    "                        w_cnt+=1\n",
    "                    document_word_vectors[f].append(word2index[w])                \n",
    "                #for line in fs:\n",
    "                #    obj = json.loads(line)\n",
    "                #    textType = obj['type']\n",
    "                #    if textType == 'paragraph':\n",
    "                #        words = textPreprocess(obj['content'])\n",
    "                #        for w in words:\n",
    "                #            if w not in word2index:\n",
    "                #                word2index[w] = w_cnt\n",
    "                #                w_cnt+=1\n",
    "                #            document_word_vectors[f].append(word2index[w])\n",
    "            except:\n",
    "                print (f)\n",
    "                        \n",
    "w_f_matrix = np.zeros((len(word2index),len(document2index)))\n",
    "for doc in document_word_vectors:\n",
    "    i = document2index[doc]\n",
    "    for j in document_word_vectors[doc]:\n",
    "        w_f_matrix[j,i]+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25377, 9)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_f_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain normalized term-frequency matrix\n",
    "t_f = np.copy(w_f_matrix)\n",
    "sum_f = np.zeros(len(document2index))\n",
    "for i in range(len(document2index)):\n",
    "    sum_f[i] = np.sum(t_f[:,i])\n",
    "t_f = np.divide(t_f,sum_f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining tf-idf matrix\n",
    "inv_doc_freq = np.count_nonzero(t_f,axis=1)\n",
    "def normalize(a,x):\n",
    "    return np.log(x/a)\n",
    "norm = np.vectorize(normalize)\n",
    "inv_doc_freq = norm(inv_doc_freq,len(document2index))\n",
    "tf_idf = np.multiply(t_f,inv_doc_freq.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.08042101e-05, 1.01532723e-05, 2.16941632e-05, ...,\n",
       "        0.00000000e+00, 1.34306036e-05, 3.38327372e-05],\n",
       "       [1.07426947e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        8.21278323e-05, 0.00000000e+00, 7.76455588e-05],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.05190759e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.05190759e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.05190759e-04]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2657,   49, 2493,   50])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.argpartition(tf_idf[:,2], -4)[-4:]\n",
    "index = index[np.argsort(tf_idf[:, 2][index])]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/6910641/how-do-i-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "\n",
    "def find_top_k_words(tf_idf, k):\n",
    "    for i in range(tf_idf.shape[1]):\n",
    "        freq_words = []\n",
    "        index = np.argpartition(tf_idf[:, i], -k)[-k:]\n",
    "        index = index[np.argsort(tf_idf[:, i][index])]\n",
    "        print('Most frequent words in: ', index2document[i])\n",
    "        for ind in index:\n",
    "            freq_words.append(list(word2index.keys())[list(word2index.values()).index(ind)])\n",
    "        print(freq_words)\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent words in:  BVB-AnnualReport-2016.txt\n",
      "['iduna', '20152016', 'saison', 'bvb', 'fc', 'league', 'uefa', 'teur', 'borussia', 'dortmund']\n",
      "Most frequent words in:  CarlZeissMeditec-AnnualReport-2017.txt\n",
      "['ärzte', 'veracity', 'devices', 'ophthalmic', 'patienten', 'tsd', '201617', 'meditec', 'carl', 'zeiss']\n",
      "Most frequent words in:  BVB-AnnualReport-2015.txt\n",
      "['mannschaft', 'league', 'iduna', 'uefa', 'saison', 'eur', '20142015', 'borussia', 'teur', 'dortmund']\n",
      "Most frequent words in:  BVB-AnnualReport-2017.txt\n",
      "['bvb', 'uefa', 'iduna', 'saison', '20162017', '20172018', 'eur', 'borussia', 'teur', 'dortmund']\n",
      "Most frequent words in:  BMW-AnnualReport-2015.txt\n",
      "['vorzugsaktien', 'fahrzeug', 'modelle', 'motorräder', 'fahrzeuge', 'mio', 'mini', 'group', 'automobile', 'bmw']\n",
      "Most frequent words in:  BMW-AnnualReport-2017.txt\n",
      "['rollsroyce', 'mio', 'vorzugsaktien', 'motorräder', 'fahrzeug', 'group', 'fahrzeuge', 'mini', 'automobile', 'bmw']\n",
      "Most frequent words in:  CarlZeissMeditec-AnnualReport-2015.txt\n",
      "['patienten', 'geschäftseinheit', 'diagnose', 'jena', 'oraya', 'vj', 'tsd', 'meditec', 'carl', 'zeiss']\n",
      "Most frequent words in:  BMW-AnnualReport-2016.txt\n",
      "['rollsroyce', 'mio', 'vorzugsaktien', 'motorräder', 'fahrzeug', 'group', 'fahrzeuge', 'mini', 'automobile', 'bmw']\n",
      "Most frequent words in:  CarlZeissMeditec-AnnualReport-2016.txt\n",
      "['devices', 'ophthalmic', 'sbu', 'patienten', 'vj', 'tsd', '201516', 'meditec', 'carl', 'zeiss']\n"
     ]
    }
   ],
   "source": [
    "find_top_k_words(tf_idf, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
