{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Generation\n",
    "\n",
    "After preprocessing, we want to generate text corpus for each document, which consists of a list of duplicated words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Run 02-Preprocessing.ipynb first, to make sure preprocessing function can be invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 02-Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Generate Coupus for each document\n",
    "\n",
    "- target_corpus: folder to save the corpus for each document (/spacy_corpus folder)\n",
    "- source_folder: folder contain Pre-extracted TXT files (/txt_data folder)\n",
    "- spacyFlag: default: True, if set as True, to use spacy preprocessing, otherwise using nltk preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generateCorpus(target_corpus, source_folder, spacyFlag=True):\n",
    "    \n",
    "    if not os.path.exists(target_corpus):\n",
    "        os.makedirs(target_corpus)\n",
    "    \n",
    "    #monitor the file process\n",
    "    progress = 0\n",
    "    progress_count = 0\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        file_count = len(files)\n",
    "        for f in files:\n",
    "            progress += 1\n",
    "            progress_count += 1\n",
    "            try:\n",
    "                with open(root+'/'+f) as fr:\n",
    "                    text = fr.read()\n",
    "                    if spacyFlag == False:\n",
    "                        tokens = nltkPreprocessing(text)\n",
    "                    if spacyFlag == True:\n",
    "                        tokens = preprocessing_spacy(text)\n",
    "            except:\n",
    "                print('Error while processing file: ', f)\n",
    "            \n",
    "            \n",
    "            with open(target_corpus+f, 'wb+') as fw:\n",
    "                    #use pickle library to dump list to file\n",
    "                    pickle.dump(tokens, fw)\n",
    "\n",
    "            if progress_count % 400 == 0:\n",
    "                print('{0}% of total files has been processed'.format(round(progress/file_count*100), 2))\n",
    "                print('running time: {0}'.format(time.process_time() - start_time))\n",
    "\n",
    "            if progress_count == file_count:\n",
    "                print('all files has been processed')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while processing file:  Thyssenkrupp-QuarterlyReport-2014-Q1\n",
      "Error while processing file:  Capital_Stage-QuarterlyReport-2013-Q1\n",
      "Error while processing file:  Medigene-QuarterlyReport-2017-Q1\n",
      "9% of total files has been processed\n",
      "running time: 1579.457106566\n",
      "Error while processing file:  Deutsche_Euroshop-QuarterlyReport-2011-Q1\n",
      "Error while processing file:  METRO-QuarterlyReport-2013-Q2\n",
      "Error while processing file:  SmaSolarTechnology-AnnualReport-2016\n",
      "Error while processing file:  Telekom-QuarterlyReport-2011-Q2\n",
      "Error while processing file:  Thyssenkrupp-QuarterlyReport-2014-Q2\n",
      "Error while processing file:  KloecknerCo-QuarterlyReport-2017-Q1\n",
      "Error while processing file:  Deutsche_Euroshop-QuarterlyReport-2017-Q1\n",
      "18% of total files has been processed\n",
      "running time: 3123.385093344\n",
      "Error while processing file:  PATRIZIA-QuarterlyReport-2017-Q1\n",
      "Error while processing file:  Tele_Columbus-QuarterlyReport-2015-Q2\n",
      "Error while processing file:  KloecknerCo-QuarterlyReport-2016-Q3\n",
      "Error while processing file:  Medigene-QuarterlyReport-2016-Q3\n",
      "Error while processing file:  MorphoSys-QuarterlyReport-2017-Q1\n",
      "27% of total files has been processed\n",
      "running time: 4663.368269858\n",
      "Error while processing file:  Medigene-QuarterlyReport-2017-Q2\n",
      "Error while processing file:  Telekom-QuarterlyReport-2012-Q3\n",
      "Error while processing file:  SlmSolutionsGroup-QuarterlyReport-2015-Q2\n",
      "Error while processing file:  Thyssenkrupp-QuarterlyReport-2016-Q3\n",
      "Error while processing file:  Steinhoff-QuarterlyReport-2011-Q2\n",
      "Error while processing file:  MorphoSys-QuarterlyReport-2016-Q1\n",
      "36% of total files has been processed\n",
      "running time: 6446.799738138\n",
      "Error while processing file:  KloecknerCo-QuarterlyReport-2016-Q2\n",
      "Error while processing file:  SlmSolutionsGroup-QuarterlyReport-2015-Q3\n",
      "Error while processing file:  WCM-QuarterlyReport-2014-Q2\n",
      "Error while processing file:  MorphoSys-QuarterlyReport-2012-Q3\n",
      "Error while processing file:  Telekom-QuarterlyReport-2012-Q1\n",
      "45% of total files has been processed\n",
      "running time: 8154.399928988\n",
      "54% of total files has been processed\n",
      "running time: 9755.888305903001\n",
      "Error while processing file:  MLP-AnnualReport-2015\n",
      "Error while processing file:  Thyssenkrupp-QuarterlyReport-2014-Q3\n",
      "63% of total files has been processed\n",
      "running time: 11519.791173765001\n",
      "Error while processing file:  KloecknerCo-QuarterlyReport-2013-Q3\n",
      "72% of total files has been processed\n",
      "running time: 13074.035039419\n",
      "Error while processing file:  Telekom-QuarterlyReport-2011-Q3\n",
      "Error while processing file:  DIC-Asset-QuarterlyReport-2010-Q2\n",
      "Error while processing file:  Beiersdorf-QuarterlyReport-2016-Q1\n",
      "81% of total files has been processed\n",
      "running time: 14679.497686088002\n",
      "Error while processing file:  Thyssenkrupp-QuarterlyReport-2017-Q2\n",
      "Error while processing file:  WCM-QuarterlyReport-2013-Q1\n",
      "Error while processing file:  SAF-Holland-QuarterlyReport-2012-Q3\n",
      "90% of total files has been processed\n",
      "running time: 16271.869072291001\n",
      "Error while processing file:  Telekom-QuarterlyReport-2012-Q2\n",
      "Error while processing file:  WCM-QuarterlyReport-2016-Q1\n",
      "99% of total files has been processed\n",
      "running time: 17985.427776083\n",
      "Error while processing file:  RhoenKlinikum-QuarterlyReport-2011-Q1\n",
      "all files has been processed\n",
      "CPU times: user 4h 41min 55s, sys: 20min 16s, total: 5h 2min 12s\n",
      "Wall time: 47min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#please modify the path\n",
    "# target_corpus = '/home/bit/ma0/LabShare/data/chui_ma/spacy_corpus/'\n",
    "# source_folder = '/home/bit/ma0/LabShare/data/chui_ma/txt_data/'\n",
    "\n",
    "#relative folder path\n",
    "target_corpus = '../spacy_corpus/'\n",
    "source_folder = '../txt_data/'\n",
    "\n",
    "generateCorpus(target_corpus, source_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
