{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Generation\n",
    "\n",
    "After preprocessing, we want to generate text corpus for each document, which consists of a list of potentially duplicated words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"/>\n",
    "\n",
    "### dsp:\n",
    "  * You mean \"potentially duplicated words\"? The list may as well contain words that are not duplicated &#x1f609;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Run 02-Preprocessing.ipynb first, to make sure preprocessing function can be invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 303 ms, sys: 3.94 ms, total: 307 ms\n",
      "Wall time: 78.7 ms\n",
      "CPU times: user 1.37 s, sys: 75.1 ms, total: 1.45 s\n",
      "Wall time: 534 ms\n"
     ]
    }
   ],
   "source": [
    "%run 02-Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Generate Coupus for each document\n",
    "\n",
    "- source_folder: folder contain Pre-extracted TXT files (/txt_data folder)\n",
    "- corpus_folder: folder to save the corpus for each document (/spacy_corpus folder)\n",
    "- spacyFlag: default: True, if set as True, to use spacy preprocessing, otherwise using nltk preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCorpus(source_folder, corpus_folder, preprocessor=spacyPreprocessing):\n",
    "    os.makedirs(corpus_folder, exist_ok=True)\n",
    "    # monitor the file process\n",
    "    progress_count = 0\n",
    "\n",
    "    start_time = time.process_time()\n",
    "\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        file_count = len(files)\n",
    "        for file in files:\n",
    "            progress_count += 1\n",
    "            tokens = []\n",
    "\n",
    "            try:\n",
    "                with open(root+'/'+file) as fr:\n",
    "                    text = fr.read()\n",
    "                    tokens = preprocessor(text)\n",
    "            except:\n",
    "                print('Error while processing file: ', file)\n",
    "\n",
    "            with open(corpus_folder+file, 'wb') as fw:\n",
    "                pickle.dump(tokens, fw)\n",
    "\n",
    "            if progress_count % 200 == 0:\n",
    "                print('{:6.2%} of the total files have been processed'.format(\n",
    "                    progress_count/file_count), end='\\r')\n",
    "                break\n",
    "\n",
    "            if progress_count == file_count:\n",
    "                print('all files have been processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"/>\n",
    "\n",
    "### dsp:\n",
    "  * The names `target_corpus` and `source_folder` seem to indicate that the first is some object/data structure while the second is a folder. That's confusing. Suggestion: Rename `target_corpus` to `corpus_folder`. Or maybe you find something even better.\n",
    "  * For me the parameter order 1) source 2) target feels more natural, but this might depend on the context.\n",
    "  * Flag parameters are always worth a second look. In your case you code depends on the NLTK even, when you do not use it. If it is a considerable option to add another pre-processing, you would need to change the type of `spacyFlag`. You might consider to pass the actual pre-processing functions (Signature: (str) -> (list(str))) as  a parameter, like: `def generateCorpus(source_folder, corpus_folder, preprocessor=spacy_preprocessing):`  and later `tokens = preprocessor(text)`.\n",
    "  * What is the difference between `progress` and `progress_count`?\n",
    "  * Are you sure, you want to store the tokens, even when there was an exception?  \n",
    "  * Call `f` `file`. My eyes needed to jump around to understand what `f` stands for.\n",
    "  * With `os.makedirs(name, exist_ok=True)` you don't need the existance check. (But that's a matter of taste.)\n",
    "  * The comment `#use pickle library to dump list to file` before `pickle.dump(tokens, fw)` justs states the obvious to me.\n",
    "  * \"all files has\" ~> \"all files have\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.08% of the total files have been processed\r",
      "CPU times: user 10min 24s, sys: 44.1 s, total: 11min 8s\n",
      "Wall time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#please modify the path\n",
    "# corpus_folder = '/home/bit/ma0/LabShare/data/chui_ma/spacy_corpus/'\n",
    "# source_folder = '/home/bit/ma0/LabShare/data/chui_ma/txt_data/'\n",
    "\n",
    "#relative folder path\n",
    "corpus_folder = '../spacy_corpus/'\n",
    "source_folder = '../txt_data/'\n",
    "\n",
    "# use spacyPreprocessing\n",
    "generateCorpus(source_folder, corpus_folder, spacyPreprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating corpus, we would like to do some expriments on [TF-IDF](04-TF-IDF_Raw_Implementation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"/>\n",
    "\n",
    "### dsp:\n",
    "  * Either concentrate the variables that need modification in a separate file or at the beginning of the Notebook.\n",
    "  * The hint to \"Convert JSON to TXT\" is probably as well more natural at the beginning of the Notebook, as you did in the next Notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
