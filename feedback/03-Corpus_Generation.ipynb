{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Generation\n",
    "\n",
    "After preprocessing, we want to generate text corpus for each document, which consists of a list of duplicated words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"/>\n",
    "\n",
    "### dsp:\n",
    "  * You mean \"potentially duplicated words\"? The list may as well contain words that are not duplicated &#x1f609;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Run 02-Preprocessing.ipynb first, to make sure preprocessing function can be invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 02-Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Generate Coupus for each document\n",
    "\n",
    "- target_corpus: folder to save the corpus for each document (/spacy_corpus folder)\n",
    "- source_folder: folder contain Pre-extracted TXT files (/txt_data folder)\n",
    "- spacyFlag: default: True, if set as True, to use spacy preprocessing, otherwise using nltk preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCorpus(target_corpus, source_folder, spacyFlag=True):\n",
    "    if not os.path.exists(target_corpus):\n",
    "        os.makedirs(target_corpus)\n",
    "    \n",
    "    #monitor the file process\n",
    "    progress = 0\n",
    "    progress_count = 0\n",
    "    \n",
    "    start_time = time.process_time()\n",
    "\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        file_count = len(files)\n",
    "        for f in files:\n",
    "            progress += 1\n",
    "            progress_count += 1\n",
    "            tokens = []\n",
    "            \n",
    "            try:\n",
    "                with open(root+'/'+f) as fr:\n",
    "                    text = fr.read()\n",
    "                    if spacyFlag == False:\n",
    "                        tokens = nltkPreprocessing(text)\n",
    "                    if spacyFlag == True:\n",
    "                        tokens = spacyPreprocessing(text)\n",
    "            except:\n",
    "                print('Error while processing file: ', f)\n",
    "            \n",
    "            \n",
    "            with open(target_corpus+f, 'wb') as fw:\n",
    "                    #use pickle library to dump list to file\n",
    "                    pickle.dump(tokens, fw)\n",
    "\n",
    "            if progress_count % 400 == 0:\n",
    "                print('{0}% of total files has been processed'.format(round(progress/file_count*100), 2))\n",
    "                print('running time: {0}'.format(time.process_time() - start_time))\n",
    "\n",
    "            if progress_count == file_count:\n",
    "                print('all files has been processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"/>\n",
    "\n",
    "### dsp:\n",
    "  * The names `target_corpus` and `source_folder` seem to indicate that the first is some object/data structure while the second is a folder. That's confusing. Suggestion: Rename `target_corpus` to `corpus_folder`. Or maybe you find something even better.\n",
    "  * For me the parameter order 1) source 2) target feels more natural, but this might depend on the context.\n",
    "  * Flag parameters are always worth a second look. In your case you code depends on the NLTK even, when you do not use it. If it is a considerable option to add another pre-processing, you would need to change the type of `spacyFlag`. You might consider to pass the actual pre-processing functions (Signature: (str) -> (list(str))) as  a parameter, like: `def generateCorpus(source_folder, corpus_folder, preprocessor=spacy_preprocessing):`  and later `tokens = preprocessor(text)`.\n",
    "  * What is the difference between `progress` and `progress_count`?\n",
    "  * Are you sure, you want to store the tokens, even when there was an exception?  \n",
    "  * Call `f` `file`. My eyes needed to jump around to understand what `f` stands for.\n",
    "  * With `os.makedirs(name, exist_ok=True)` you don't need the existance check. (But that's a matter of taste.)\n",
    "  * The comment `#use pickle library to dump list to file` before `pickle.dump(tokens, fw)` justs states the obvious to me.\n",
    "  * \"all files has\" ~> \"all files have\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the snippets below, make sure those txt files are prepared. If not, go to [Convert JSON to TXT](01-Convert_JSON_to_TXT.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#please modify the path\n",
    "# target_corpus = '/home/bit/ma0/LabShare/data/chui_ma/spacy_corpus/'\n",
    "# source_folder = '/home/bit/ma0/LabShare/data/chui_ma/txt_data/'\n",
    "\n",
    "#relative folder path\n",
    "target_corpus = '../spacy_corpus/'\n",
    "source_folder = '../txt_data/'\n",
    "\n",
    "generateCorpus(target_corpus, source_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"/>\n",
    "\n",
    "### dsp:\n",
    "  * Either concentrate the variables that need modification in a separate file or at the beginning of the Notebook.\n",
    "  * The hint to \"Convert JSON to TXT\" is probably as well more natural at the beginning of the Notebook, as you did in the next Notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
